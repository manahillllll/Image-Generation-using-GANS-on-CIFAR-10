{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ay0bBTkKrnjb"
      },
      "outputs": [],
      "source": [
        "#Name : Manahil Sarwar\n",
        "#Section : AI-K\n",
        "#Roll No: 21I-0293"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SehqNBNErm_g"
      },
      "outputs": [],
      "source": [
        "#Loading Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import numpy as np\n",
        "from torch.nn.utils import spectral_norm\n",
        "import torch.optim as optim\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG-c5L9FICqH",
        "outputId": "8a1482e6-7983-4264-9f50-00bbc3f19a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [01:20<00:00, 2120566.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#Data Preprocessing\n",
        "#Define transformations\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    ])\n",
        "\n",
        "#Load CIFAR-10 training and test datasets\n",
        "train_dataset=torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
        "test_dataset=torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
        "\n",
        "#Function to filter dataset for cats and dogs\n",
        "def filter_cats_dogs(dataset):\n",
        "    targets=np.array(dataset.targets)\n",
        "    mask=(targets==3)|(targets==5)\n",
        "    indices=np.where(mask)[0]\n",
        "    return Subset(dataset,indices)\n",
        "\n",
        "#Filter datasets\n",
        "train_subset=filter_cats_dogs(train_dataset)\n",
        "test_subset=filter_cats_dogs(test_dataset)\n",
        "\n",
        "#DataLoaders\n",
        "batch_size=128\n",
        "train_loader=DataLoader(train_subset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
        "test_loader=DataLoader(test_subset,batch_size=batch_size,shuffle=False,num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Xv_l65TYID47"
      },
      "outputs": [],
      "source": [
        "#Generator Class\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self,nz=100,ngf=64,nc=3):\n",
        "        super(Generator,self).__init__()\n",
        "        self.main=nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz,ngf*4,4,1,0,bias=False),\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.ConvTranspose2d(ngf*4,ngf*2,4,2,1,bias=False),\n",
        "            nn.BatchNorm2d(ngf*2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.ConvTranspose2d(ngf*2,ngf,4,2,1,bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.ConvTranspose2d(ngf,nc,4,2,1,bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sD3OiXCXIFvW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000001C742769DA0>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1477, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1435, in _shutdown_workers\n",
            "    if self._persistent_workers or self._workers_status[worker_id]:\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
          ]
        }
      ],
      "source": [
        "#Discriminator Class\n",
        "class MinibatchDiscrimination(nn.Module):\n",
        "    def __init__(self,in_features,num_kernels,kernel_dim=10):\n",
        "        super(MinibatchDiscrimination,self).__init__()\n",
        "        self.num_kernels=num_kernels\n",
        "        self.T=nn.Parameter(torch.randn(in_features,num_kernels*kernel_dim))\n",
        "\n",
        "    def forward(self,x):\n",
        "        M=x.mm(self.T)\n",
        "        M=M.view(-1,self.num_kernels,M.size(1)//self.num_kernels)\n",
        "        out=M.unsqueeze(0)-M.unsqueeze(1)\n",
        "        out=torch.exp(-torch.abs(out).sum(3)) \n",
        "        out=out.sum(1)\n",
        "        return torch.cat([x,out],dim=1)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,nc=3,ndf=64):\n",
        "        super(Discriminator,self).__init__()\n",
        "        self.shared_conv=nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(nc,ndf,4,2,1,bias=False)),\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "            spectral_norm(nn.Conv2d(ndf,ndf*2,4,2,1,bias=False)),\n",
        "            nn.BatchNorm2d(ndf*2),\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "            spectral_norm(nn.Conv2d(ndf*2,ndf*4,4,2,1,bias=False)),\n",
        "            nn.BatchNorm2d(ndf*4),\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        \n",
        "        self.minibatch_discrimination=MinibatchDiscrimination(in_features=8192,num_kernels=10)\n",
        "        self.fc=nn.Sequential(\n",
        "            nn.Linear(8202,512),  \n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "            nn.Linear(512,1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self,real_img,fake_img):\n",
        "        real_feat=self.shared_conv(real_img)\n",
        "        fake_feat=self.shared_conv(fake_img)\n",
        "        combined=torch.cat((real_feat,fake_feat),dim=1)\n",
        "        combined=self.minibatch_discrimination(combined)\n",
        "        similarity=self.fc(combined)\n",
        "        return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJOKYwQSIHy_",
        "outputId": "bfb5b6b3-89f8-4630-a462-8d43306cd768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 1/79 [00:17<22:09, 17.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/25] Batch 0/79                   Loss D: 1.4082, Loss G: 3.0292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:23<00:00,  1.81s/it]\n",
            "  1%|▏         | 1/79 [00:15<20:12, 15.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/25] Batch 0/79                   Loss D: 0.4443, Loss G: 10.5247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:07<00:00,  1.61s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:19, 13.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/25] Batch 0/79                   Loss D: 0.5045, Loss G: 6.5007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:04<00:00,  1.57s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:14, 13.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/25] Batch 0/79                   Loss D: 0.3513, Loss G: 8.0415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:03<00:00,  1.56s/it]\n",
            "  1%|▏         | 1/79 [00:12<16:52, 12.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/25] Batch 0/79                   Loss D: 0.3500, Loss G: 8.7940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:03<00:00,  1.56s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:08, 13.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/25] Batch 0/79                   Loss D: 0.5031, Loss G: 8.4168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:03<00:00,  1.56s/it]\n",
            "  1%|▏         | 1/79 [00:13<16:56, 13.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/25] Batch 0/79                   Loss D: 0.4539, Loss G: 10.2448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:02<00:00,  1.55s/it]\n",
            "  1%|▏         | 1/79 [00:13<16:55, 13.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/25] Batch 0/79                   Loss D: 0.3625, Loss G: 10.6832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:03<00:00,  1.56s/it]\n",
            "  1%|▏         | 1/79 [00:13<16:58, 13.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/25] Batch 0/79                   Loss D: 0.3394, Loss G: 13.9798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:03<00:00,  1.56s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:27, 13.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/25] Batch 0/79                   Loss D: 0.3352, Loss G: 14.3523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:02<00:00,  1.56s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:31, 13.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/25] Batch 0/79                   Loss D: 0.3347, Loss G: 16.8262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:03<00:00,  1.56s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:12, 13.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/25] Batch 0/79                   Loss D: 0.3288, Loss G: 17.4582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:04<00:00,  1.57s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:02, 13.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/25] Batch 0/79                   Loss D: 0.3337, Loss G: 17.4468\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:04<00:00,  1.57s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:02, 13.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/25] Batch 0/79                   Loss D: 0.3365, Loss G: 19.9715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:04<00:00,  1.57s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:09, 13.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/25] Batch 0/79                   Loss D: 0.3295, Loss G: 18.8562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:03<00:00,  1.56s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:05, 13.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/25] Batch 0/79                   Loss D: 0.3302, Loss G: 19.7295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:02<00:00,  1.55s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:15, 13.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/25] Batch 0/79                   Loss D: 0.3304, Loss G: 14.9642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:03<00:00,  1.56s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:31, 13.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/25] Batch 0/79                   Loss D: 0.3274, Loss G: 18.3146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:04<00:00,  1.58s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:15, 13.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/25] Batch 0/79                   Loss D: 0.3277, Loss G: 20.0148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:02<00:00,  1.55s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:01, 13.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/25] Batch 0/79                   Loss D: 0.3336, Loss G: 19.0958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:03<00:00,  1.56s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:08, 13.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [21/25] Batch 0/79                   Loss D: 0.3267, Loss G: 22.4314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:03<00:00,  1.57s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:22, 13.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [22/25] Batch 0/79                   Loss D: 0.3261, Loss G: 19.9452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:06<00:00,  1.60s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:09, 13.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [23/25] Batch 0/79                   Loss D: 0.3269, Loss G: 19.6826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:03<00:00,  1.56s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:12, 13.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [24/25] Batch 0/79                   Loss D: 0.3262, Loss G: 20.0438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:04<00:00,  1.58s/it]\n",
            "  1%|▏         | 1/79 [00:13<17:09, 13.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [25/25] Batch 0/79                   Loss D: 0.3275, Loss G: 20.6584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [02:02<00:00,  1.55s/it]\n"
          ]
        }
      ],
      "source": [
        "#Training the Gan\n",
        "criterion=nn.BCELoss()\n",
        "#Labels\n",
        "real_label=1.0\n",
        "fake_label=0.0\n",
        "#Check device\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "#Parameters\n",
        "ndf=64\n",
        "num_epochs=25\n",
        "lr=0.0002\n",
        "beta1=0.5\n",
        "nz=128\n",
        "#Initialize generator and discriminator\n",
        "ngf=128\n",
        "netG=Generator(nz,ngf,nc=3).to(device)\n",
        "netD=Discriminator(nc=3,ndf=ndf).to(device)\n",
        "\n",
        "#Initialize weights\n",
        "def weights_init(m):\n",
        "    classname=m.__class__.__name__\n",
        "    if classname.find('Conv')!=-1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm')!=-1:\n",
        "        nn.init.normal_(m.weight.data,1.0,0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "netG.apply(weights_init)\n",
        "netD.apply(weights_init)\n",
        "\n",
        "#Optimizers\n",
        "optimizerD=optim.Adam(netD.parameters(),lr=lr,betas=(beta1,0.999))\n",
        "optimizerG=optim.Adam(netG.parameters(),lr=lr,betas=(beta1,0.999))\n",
        "\n",
        "\n",
        "#Fixed noise for generating samples\n",
        "fixed_noise=torch.randn(64,nz,1,1,device=device)\n",
        "#Directory to save generated images\n",
        "os.makedirs('C:/Users/HP/Downloads/output_images',exist_ok=True)\n",
        "#Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(tqdm(train_loader),0):\n",
        "        #Update Discriminator\n",
        "        netD.zero_grad()\n",
        "        #Format batch\n",
        "        real_images,_=data\n",
        "        batch_size_curr=real_images.size(0)\n",
        "        real_images=real_images.to(device)\n",
        "        real_images=real_images+0.05 * torch.randn_like(real_images).to(device)\n",
        "\n",
        "        # Real pairs:(Real,Real)\n",
        "        real_pairs=(real_images,real_images)\n",
        "        label_real=torch.full((batch_size_curr,1),0.9,dtype=torch.float,device=device)\n",
        "\n",
        "        output_real=netD(*real_pairs)\n",
        "        lossD_real=criterion(output_real,label_real)\n",
        "        lossD_real.backward()\n",
        "\n",
        "        #Fake pairs: (Real,Fake)\n",
        "        noise=torch.randn(batch_size_curr,nz,1,1,device=device)\n",
        "        fake_images=netG(noise)\n",
        "\n",
        "        fake_images=fake_images+0.05*torch.randn_like(fake_images).to(device)\n",
        "        fake_pairs=(real_images,fake_images.detach())\n",
        "        label_fake=torch.full((batch_size_curr,1),fake_label,dtype=torch.float,device=device)\n",
        "\n",
        "        output_fake=netD(*fake_pairs)\n",
        "        lossD_fake=criterion(output_fake,label_fake)\n",
        "        lossD_fake.backward()\n",
        "\n",
        "        lossD=lossD_real+lossD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        #Update Generator\n",
        "        netG.zero_grad()\n",
        "        #Generator wants D to output real labels for fake pairs\n",
        "        label_gen=torch.full((batch_size_curr,1),real_label,dtype=torch.float,device=device)\n",
        "        fake_pairs_for_G=(real_images,fake_images)\n",
        "        output_gen=netD(*fake_pairs_for_G)\n",
        "        lossG=criterion(output_gen,label_gen)\n",
        "        lossG.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        #Print statistics\n",
        "        if i%100==0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}] Batch {i}/{len(train_loader)} \\\n",
        "                  Loss D: {lossD.item():.4f}, Loss G: {lossG.item():.4f}')\n",
        "\n",
        "    #Save generated images every epoch\n",
        "    with torch.no_grad():\n",
        "        fake=netG(fixed_noise).detach().cpu()\n",
        "    fake=fake*0.5+0.5\n",
        "    save_image(fake,f'C:/Users/HP/Downloads/output_images/fake_epoch_{epoch+1}.png', nrow=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OeS80RSPIJrb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete and models saved.\n"
          ]
        }
      ],
      "source": [
        "#Save the models\n",
        "torch.save(netG.state_dict(),'C:/Users/HP/Downloads/netG.pth')\n",
        "torch.save(netD.state_dict(),'C:/Users/HP/Downloads/netD.pth')\n",
        "\n",
        "print(\"Training complete and models saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7EZqzDgubRB1"
      },
      "outputs": [],
      "source": [
        "\n",
        "with torch.no_grad():\n",
        "    netG.eval()\n",
        "    fake=netG(fixed_noise).detach().cpu()\n",
        "    save_image(fake,f'C:/Users/HP/Downloads/output_images/testoutput.png',normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
